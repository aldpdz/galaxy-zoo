{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Reshape, Flatten, Dropout, Activation\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers, callbacks\n",
    "from skimage.transform import resize\n",
    "from imageio import imread\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(np_img):\n",
    "    np_img = np_img / 255\n",
    "    \n",
    "    # randome data augmentation\n",
    "    aug = np.random.choice([0, 1])\n",
    "    if aug == True:\n",
    "        seq = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5)])\n",
    "        np_img = seq.augment_image(np_img)\n",
    "        \n",
    "        # Zoom out randomly\n",
    "        if np.random.choice([True, False]):\n",
    "            seq = iaa.Sequential([iaa.Affine(scale={\"x\": (1.4, 1.4), \"y\": (1.4, 1.4)})])\n",
    "            np_img = seq.augment_image(np_img)\n",
    "        \n",
    "    return np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(path_images, labels, batch_size):\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        for i in range(batch_size):\n",
    "            # Read image\n",
    "            name_img = labels[count][0] + '.jpg'\n",
    "            img = imread(path_images + '/' + name_img)\n",
    "            \n",
    "            # Image preprocessing\n",
    "            img = preprocess_input(img)\n",
    "\n",
    "            label = labels[count][1:]\n",
    "\n",
    "            batch_features.append(img)\n",
    "            batch_labels.append(label)\n",
    "            count += 1\n",
    "            \n",
    "            # Restart counter when it has reached the size \n",
    "            # of the data set\n",
    "            if count == labels.shape[0] - 1:\n",
    "                count = 0\n",
    "                break\n",
    "            \n",
    "        yield np.array(batch_features), np.array(batch_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_predictions(path_images, list_names, batch_size):\n",
    "    size_list = list_names.shape[0] - 1\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        for i in range(batch_size):\n",
    "            # Read image\n",
    "            name_img = list_names[count]\n",
    "            img = imread(path_images + '/' + name_img)\n",
    "            \n",
    "            # Image preprocessing\n",
    "            img = preprocess_input(img)\n",
    "\n",
    "            batch_features.append(img)\n",
    "            \n",
    "            # Restart counter when it has reached the size \n",
    "            # of the data set\n",
    "            if count == size_list:\n",
    "                count = 0\n",
    "                yield np.array(batch_features)\n",
    "            count += 1\n",
    "            \n",
    "        yield np.array(batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_cnn(input_size, output_size, drop_out=False, batch_norm=False, dense_size=1024):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_size))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "    if drop_out:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "    if drop_out:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.load(path_data + 'y_train.npy')\n",
    "labels_test = np.load(path_data + 'y_test.npy')\n",
    "labels_val = np.load(path_data + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_size = [1024, 2048]\n",
    "drop_o = [True]\n",
    "batch_n = [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = 43104 // batch_size \n",
    "steps_va = 9237 // batch_size\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  model_Dense_1024_Drop_out_True_Batch_n_False\n",
      "Epoch 1/20\n",
      "1347/1347 [==============================] - 144s 107ms/step - loss: 0.0256 - rmse: 0.1571 - val_loss: 0.0186 - val_rmse: 0.1359\n",
      "Epoch 2/20\n",
      "1347/1347 [==============================] - 132s 98ms/step - loss: 0.0185 - rmse: 0.1356 - val_loss: 0.0160 - val_rmse: 0.1262\n",
      "Epoch 3/20\n",
      "1347/1347 [==============================] - 131s 97ms/step - loss: 0.0157 - rmse: 0.1248 - val_loss: 0.0134 - val_rmse: 0.1155\n",
      "Epoch 4/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0138 - rmse: 0.1172 - val_loss: 0.0122 - val_rmse: 0.1101\n",
      "Epoch 5/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0127 - rmse: 0.1125 - val_loss: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 6/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0121 - rmse: 0.1096 - val_loss: 0.0112 - val_rmse: 0.1053\n",
      "Epoch 7/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0116 - rmse: 0.1073 - val_loss: 0.0108 - val_rmse: 0.1034\n",
      "Epoch 8/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0111 - rmse: 0.1052 - val_loss: 0.0106 - val_rmse: 0.1027\n",
      "Epoch 9/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0107 - rmse: 0.1032 - val_loss: 0.0102 - val_rmse: 0.1008\n",
      "Epoch 10/20\n",
      "1347/1347 [==============================] - 133s 99ms/step - loss: 0.0104 - rmse: 0.1018 - val_loss: 0.0102 - val_rmse: 0.1006\n",
      "Epoch 11/20\n",
      "1347/1347 [==============================] - 132s 98ms/step - loss: 0.0102 - rmse: 0.1005 - val_loss: 0.0103 - val_rmse: 0.1010\n",
      "Epoch 12/20\n",
      "1347/1347 [==============================] - 130s 97ms/step - loss: 0.0099 - rmse: 0.0992 - val_loss: 0.0097 - val_rmse: 0.0980\n",
      "Epoch 13/20\n",
      "1347/1347 [==============================] - 130s 97ms/step - loss: 0.0097 - rmse: 0.0983 - val_loss: 0.0100 - val_rmse: 0.0995\n",
      "Epoch 14/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0095 - rmse: 0.0971 - val_loss: 0.0095 - val_rmse: 0.0970\n",
      "Epoch 15/20\n",
      "1347/1347 [==============================] - 131s 97ms/step - loss: 0.0093 - rmse: 0.0962 - val_loss: 0.0097 - val_rmse: 0.0980\n",
      "Epoch 16/20\n",
      "1347/1347 [==============================] - 130s 97ms/step - loss: 0.0091 - rmse: 0.0953 - val_loss: 0.0095 - val_rmse: 0.0970\n",
      "Epoch 17/20\n",
      "1347/1347 [==============================] - 131s 97ms/step - loss: 0.0090 - rmse: 0.0945 - val_loss: 0.0093 - val_rmse: 0.0961\n",
      "Epoch 18/20\n",
      "1347/1347 [==============================] - 130s 97ms/step - loss: 0.0088 - rmse: 0.0935 - val_loss: 0.0092 - val_rmse: 0.0957\n",
      "Epoch 19/20\n",
      "1347/1347 [==============================] - 131s 97ms/step - loss: 0.0086 - rmse: 0.0927 - val_loss: 0.0092 - val_rmse: 0.0954\n",
      "Epoch 20/20\n",
      "1347/1347 [==============================] - 131s 97ms/step - loss: 0.0085 - rmse: 0.0920 - val_loss: 0.0090 - val_rmse: 0.0942\n",
      "model_Dense_1024_Drop_out_True_Batch_n_False\n",
      "Evaluation: [0.009056658674606349, 0.09478867914844671]\n",
      "Training model:  model_Dense_1024_Drop_out_True_Batch_n_True\n",
      "Epoch 1/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0228 - rmse: 0.1490 - val_loss: 0.0144 - val_rmse: 0.1198\n",
      "Epoch 2/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0163 - rmse: 0.1275 - val_loss: 0.0136 - val_rmse: 0.1161\n",
      "Epoch 3/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0146 - rmse: 0.1205 - val_loss: 0.0149 - val_rmse: 0.1218\n",
      "Epoch 4/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0134 - rmse: 0.1156 - val_loss: 0.0134 - val_rmse: 0.1153\n",
      "Epoch 5/20\n",
      "1347/1347 [==============================] - 135s 101ms/step - loss: 0.0126 - rmse: 0.1122 - val_loss: 0.0119 - val_rmse: 0.1089\n",
      "Epoch 6/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0121 - rmse: 0.1097 - val_loss: 0.0117 - val_rmse: 0.1080\n",
      "Epoch 7/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0115 - rmse: 0.1072 - val_loss: 0.0110 - val_rmse: 0.1047\n",
      "Epoch 8/20\n",
      "1347/1347 [==============================] - 135s 100ms/step - loss: 0.0112 - rmse: 0.1055 - val_loss: 0.0116 - val_rmse: 0.1075\n",
      "Epoch 9/20\n",
      "1347/1347 [==============================] - 135s 101ms/step - loss: 0.0109 - rmse: 0.1042 - val_loss: 0.0110 - val_rmse: 0.1043\n",
      "Epoch 10/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0106 - rmse: 0.1027 - val_loss: 0.0107 - val_rmse: 0.1029\n",
      "Epoch 11/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0103 - rmse: 0.1013 - val_loss: 0.0103 - val_rmse: 0.1011\n",
      "Epoch 12/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0101 - rmse: 0.1002 - val_loss: 0.0105 - val_rmse: 0.1024\n",
      "Epoch 13/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0099 - rmse: 0.0992 - val_loss: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 14/20\n",
      "1347/1347 [==============================] - 136s 101ms/step - loss: 0.0096 - rmse: 0.0980 - val_loss: 0.0100 - val_rmse: 0.0998\n",
      "Epoch 15/20\n",
      "1347/1347 [==============================] - 134s 100ms/step - loss: 0.0095 - rmse: 0.0971 - val_loss: 0.0096 - val_rmse: 0.0974\n",
      "Epoch 16/20\n",
      "1347/1347 [==============================] - 134s 100ms/step - loss: 0.0093 - rmse: 0.0963 - val_loss: 0.0109 - val_rmse: 0.1042\n",
      "Epoch 17/20\n",
      "1347/1347 [==============================] - 134s 100ms/step - loss: 0.0091 - rmse: 0.0953 - val_loss: 0.0101 - val_rmse: 0.1000\n",
      "Epoch 18/20\n",
      "1347/1347 [==============================] - 134s 100ms/step - loss: 0.0090 - rmse: 0.0944 - val_loss: 0.0097 - val_rmse: 0.0979\n",
      "Epoch 19/20\n",
      "1347/1347 [==============================] - 134s 100ms/step - loss: 0.0088 - rmse: 0.0937 - val_loss: 0.0099 - val_rmse: 0.0991\n",
      "Epoch 20/20\n",
      "1347/1347 [==============================] - 134s 100ms/step - loss: 0.0087 - rmse: 0.0932 - val_loss: 0.0093 - val_rmse: 0.0959\n",
      "model_Dense_1024_Drop_out_True_Batch_n_True\n",
      "Evaluation: [0.009343828322173455, 0.09634010511336606]\n",
      "Training model:  model_Dense_2048_Drop_out_True_Batch_n_False\n",
      "Epoch 1/20\n",
      "1347/1347 [==============================] - 147s 109ms/step - loss: 0.0235 - rmse: 0.1510 - val_loss: 0.0175 - val_rmse: 0.1319\n",
      "Epoch 2/20\n",
      "1347/1347 [==============================] - 146s 109ms/step - loss: 0.0166 - rmse: 0.1286 - val_loss: 0.0142 - val_rmse: 0.1188\n",
      "Epoch 3/20\n",
      "1347/1347 [==============================] - 146s 109ms/step - loss: 0.0139 - rmse: 0.1177 - val_loss: 0.0123 - val_rmse: 0.1104\n",
      "Epoch 4/20\n",
      "1347/1347 [==============================] - 147s 109ms/step - loss: 0.0126 - rmse: 0.1121 - val_loss: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 5/20\n",
      "1347/1347 [==============================] - 147s 109ms/step - loss: 0.0119 - rmse: 0.1086 - val_loss: 0.0111 - val_rmse: 0.1050\n",
      "Epoch 6/20\n",
      "1347/1347 [==============================] - 147s 109ms/step - loss: 0.0112 - rmse: 0.1055 - val_loss: 0.0105 - val_rmse: 0.1022\n",
      "Epoch 7/20\n",
      "1347/1347 [==============================] - 147s 109ms/step - loss: 0.0107 - rmse: 0.1032 - val_loss: 0.0103 - val_rmse: 0.1008\n",
      "Epoch 8/20\n",
      "1347/1347 [==============================] - 146s 109ms/step - loss: 0.0103 - rmse: 0.1013 - val_loss: 0.0103 - val_rmse: 0.1009\n",
      "Epoch 9/20\n",
      "1347/1347 [==============================] - 146s 109ms/step - loss: 0.0100 - rmse: 0.0997 - val_loss: 0.0101 - val_rmse: 0.1000\n",
      "Epoch 10/20\n",
      "1347/1347 [==============================] - 146s 108ms/step - loss: 0.0097 - rmse: 0.0983 - val_loss: 0.0099 - val_rmse: 0.0992\n",
      "Epoch 11/20\n",
      "1347/1347 [==============================] - 146s 108ms/step - loss: 0.0094 - rmse: 0.0968 - val_loss: 0.0097 - val_rmse: 0.0982\n",
      "Epoch 12/20\n",
      "1347/1347 [==============================] - 146s 108ms/step - loss: 0.0092 - rmse: 0.0955 - val_loss: 0.0096 - val_rmse: 0.0977\n",
      "Epoch 13/20\n",
      "1347/1347 [==============================] - 145s 108ms/step - loss: 0.0089 - rmse: 0.0942 - val_loss: 0.0094 - val_rmse: 0.0967\n",
      "Epoch 14/20\n",
      "1347/1347 [==============================] - 146s 108ms/step - loss: 0.0087 - rmse: 0.0932 - val_loss: 0.0094 - val_rmse: 0.0967\n",
      "Epoch 15/20\n",
      "1347/1347 [==============================] - 146s 108ms/step - loss: 0.0086 - rmse: 0.0925 - val_loss: 0.0091 - val_rmse: 0.0950\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/1347 [==============================] - 145s 108ms/step - loss: 0.0084 - rmse: 0.0914 - val_loss: 0.0091 - val_rmse: 0.0950\n",
      "Epoch 17/20\n",
      "1347/1347 [==============================] - 145s 108ms/step - loss: 0.0082 - rmse: 0.0905 - val_loss: 0.0091 - val_rmse: 0.0950\n",
      "Epoch 18/20\n",
      "1347/1347 [==============================] - 145s 108ms/step - loss: 0.0081 - rmse: 0.0899 - val_loss: 0.0090 - val_rmse: 0.0943\n",
      "Epoch 19/20\n",
      "1347/1347 [==============================] - 145s 108ms/step - loss: 0.0079 - rmse: 0.0889 - val_loss: 0.0087 - val_rmse: 0.0931\n",
      "Epoch 20/20\n",
      "1347/1347 [==============================] - 145s 108ms/step - loss: 0.0078 - rmse: 0.0882 - val_loss: 0.0089 - val_rmse: 0.0938\n",
      "model_Dense_2048_Drop_out_True_Batch_n_False\n",
      "Evaluation: [0.00889094145014219, 0.09391871578396142]\n",
      "Training model:  model_Dense_2048_Drop_out_True_Batch_n_True\n",
      "Epoch 1/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0206 - rmse: 0.1418 - val_loss: 0.0147 - val_rmse: 0.1211\n",
      "Epoch 2/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0150 - rmse: 0.1222 - val_loss: 0.0135 - val_rmse: 0.1159\n",
      "Epoch 3/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0134 - rmse: 0.1154 - val_loss: 0.0134 - val_rmse: 0.1155\n",
      "Epoch 4/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0124 - rmse: 0.1111 - val_loss: 0.0136 - val_rmse: 0.1163\n",
      "Epoch 5/20\n",
      "1347/1347 [==============================] - 150s 111ms/step - loss: 0.0117 - rmse: 0.1081 - val_loss: 0.0118 - val_rmse: 0.1080\n",
      "Epoch 6/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0112 - rmse: 0.1056 - val_loss: 0.0118 - val_rmse: 0.1082\n",
      "Epoch 7/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0108 - rmse: 0.1038 - val_loss: 0.0113 - val_rmse: 0.1060\n",
      "Epoch 8/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0105 - rmse: 0.1021 - val_loss: 0.0112 - val_rmse: 0.1054\n",
      "Epoch 9/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0102 - rmse: 0.1006 - val_loss: 0.0105 - val_rmse: 0.1019\n",
      "Epoch 10/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0099 - rmse: 0.0993 - val_loss: 0.0105 - val_rmse: 0.1020\n",
      "Epoch 11/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0096 - rmse: 0.0978 - val_loss: 0.0107 - val_rmse: 0.1030\n",
      "Epoch 12/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0094 - rmse: 0.0968 - val_loss: 0.0103 - val_rmse: 0.1014\n",
      "Epoch 13/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0092 - rmse: 0.0955 - val_loss: 0.0097 - val_rmse: 0.0980\n",
      "Epoch 14/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0090 - rmse: 0.0946 - val_loss: 0.0103 - val_rmse: 0.1012\n",
      "Epoch 15/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0088 - rmse: 0.0938 - val_loss: 0.0097 - val_rmse: 0.0982\n",
      "Epoch 16/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0087 - rmse: 0.0930 - val_loss: 0.0098 - val_rmse: 0.0985\n",
      "Epoch 17/20\n",
      "1347/1347 [==============================] - 150s 112ms/step - loss: 0.0086 - rmse: 0.0923 - val_loss: 0.0096 - val_rmse: 0.0974\n",
      "Epoch 18/20\n",
      "1347/1347 [==============================] - 150s 111ms/step - loss: 0.0084 - rmse: 0.0915 - val_loss: 0.0097 - val_rmse: 0.0983\n",
      "Epoch 19/20\n",
      "1347/1347 [==============================] - 150s 111ms/step - loss: 0.0083 - rmse: 0.0907 - val_loss: 0.0098 - val_rmse: 0.0984\n",
      "Epoch 20/20\n",
      "1347/1347 [==============================] - 150s 111ms/step - loss: 0.0081 - rmse: 0.0899 - val_loss: 0.0091 - val_rmse: 0.0951\n",
      "model_Dense_2048_Drop_out_True_Batch_n_True\n",
      "Evaluation: [0.009084803788115997, 0.09499374077011997]\n"
     ]
    }
   ],
   "source": [
    "for d_s in dense_size:\n",
    "    for d_o in drop_o:\n",
    "        for b_n in batch_n:\n",
    "            model_name = 'model' + '_Dense_'+ str(d_s) + '_Drop_out_' + str(d_o) + '_Batch_n_' + str(b_n)\n",
    "            print('Training model: ', model_name)\n",
    "            # Set architecture\n",
    "            opt = optimizers.Adam(lr=0.0001)\n",
    "            model = galaxy_cnn((160, 160, 3), 37, d_o, b_n, d_s)\n",
    "            model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "            tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/' + model_name, histogram_freq=0, write_graph=True, write_images=False)\n",
    "            # Train the model\n",
    "            model.fit_generator(generator(path_data + 'preprocess_img_train', labels_train, batch_size=batch_size), \n",
    "                    steps_per_epoch=steps, \n",
    "                    epochs=epochs, \n",
    "                    validation_data= generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size),\n",
    "                    validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "            # Evaluation over validation test\n",
    "            evaluation = model.evaluate_generator(generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size), steps=steps)\n",
    "            print(model_name)\n",
    "            print('Evaluation:', evaluation)\n",
    "            # Save model after training\n",
    "            model.save(path_data + 'weights/' + model_name + '_aug.h5')\n",
    "            # Clear session to free memory\n",
    "            K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model:  model_Dense_1024_Drop_out_True_Batch_n_False_aug\n",
      "Evaluating model:  model_Dense_1024_Drop_out_True_Batch_n_True_aug\n",
      "Evaluating model:  model_Dense_2048_Drop_out_True_Batch_n_False_aug\n",
      "Evaluating model:  model_Dense_2048_Drop_out_True_Batch_n_True_aug\n"
     ]
    }
   ],
   "source": [
    "model_names = []\n",
    "evaluations = []\n",
    "for d_s in dense_size:\n",
    "    for d_o in drop_o:\n",
    "        for b_n in batch_n:\n",
    "            model_name = 'model' + '_Dense_'+ str(d_s) + '_Drop_out_' + str(d_o) + '_Batch_n_' + str(b_n) + '_aug'\n",
    "            \n",
    "            print('Evaluating model: ', model_name)\n",
    "            \n",
    "            # Load the model\n",
    "            # Set architecture\n",
    "            opt = optimizers.Adam(lr=0.0001)\n",
    "            model = galaxy_cnn((160, 160, 3), 37, d_o, b_n, d_s)\n",
    "            model.load_weights(path_data + 'weights/' + model_name +'.h5')\n",
    "            model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "            \n",
    "            # Evaluate model\n",
    "            evaluation = model.evaluate_generator(generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size), steps=steps)\n",
    "\n",
    "            model_names.append(model_name)\n",
    "            evaluations.append(evaluation)\n",
    "            \n",
    "            K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = np.array(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = evaluations[:, 1]\n",
    "list_index = rmse_list.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_Dense_2048_Drop_out_True_Batch_n_False_aug 0.093947293147561\n",
      "model_Dense_1024_Drop_out_True_Batch_n_False_aug 0.09483851098556892\n",
      "model_Dense_2048_Drop_out_True_Batch_n_True_aug 0.09487932226203578\n",
      "model_Dense_1024_Drop_out_True_Batch_n_True_aug 0.09622151068429417\n"
     ]
    }
   ],
   "source": [
    "for item in list_index:\n",
    "    print(model_names[item], rmse_list[item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
