{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Reshape, Flatten, Dropout, Activation\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers, callbacks\n",
    "from skimage.transform import resize\n",
    "from imageio import imread\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(np_img):\n",
    "    np_img = np_img / 255\n",
    "    \n",
    "    # randome data augmentation\n",
    "    aug = np.random.choice([0, 1])\n",
    "    if aug == True:\n",
    "        seq = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5)])\n",
    "        np_img = seq.augment_image(np_img)\n",
    "        list_zoom = [1.4, 1.3, 1.2, 1.5]\n",
    "        # Zoom out randomly\n",
    "        if np.random.choice([True, False]):\n",
    "            random_x_f = np.random.choice(list_zoom)\n",
    "            random_x_s = np.random.choice(list_zoom)\n",
    "            random_y_f = np.random.choice(list_zoom)\n",
    "            random_y_s = np.random.choice(list_zoom)\n",
    "            seq = iaa.Sequential([iaa.Affine(scale={\"x\": (random_x_f, random_x_s), \"y\": (random_y_f, random_y_s)})])\n",
    "            np_img = seq.augment_image(np_img)\n",
    "        \n",
    "    return np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(path_images, labels, batch_size, val=False):\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        for i in range(batch_size):\n",
    "            # Read image\n",
    "            name_img = labels[count][0] + '.jpg'\n",
    "            img = imread(path_images + '/' + name_img)\n",
    "            \n",
    "            # Image preprocessing\n",
    "            if val:\n",
    "                img = img / 255\n",
    "            else:\n",
    "                img = preprocess_input(img)\n",
    "\n",
    "            label = labels[count][1:]\n",
    "\n",
    "            batch_features.append(img)\n",
    "            batch_labels.append(label)\n",
    "            count += 1\n",
    "            \n",
    "            # Restart counter when it has reached the size \n",
    "            # of the data set\n",
    "            if count == labels.shape[0] - 1:\n",
    "                count = 0\n",
    "                break\n",
    "            \n",
    "        yield np.array(batch_features), np.array(batch_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_predictions(path_images, list_names, batch_size):\n",
    "    size_list = list_names.shape[0] - 1\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        for i in range(batch_size):\n",
    "            # Read image\n",
    "            name_img = list_names[count]\n",
    "            img = imread(path_images + '/' + name_img)\n",
    "            \n",
    "            # Image preprocessing\n",
    "            img = img / 255\n",
    "\n",
    "            batch_features.append(img)\n",
    "            \n",
    "            # Restart counter when it has reached the size \n",
    "            # of the data set\n",
    "            if count == size_list:\n",
    "                count = 0\n",
    "                yield np.array(batch_features)\n",
    "            count += 1\n",
    "            \n",
    "        yield np.array(batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_cnn(input_size, output_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_size))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_cnn_2(input_size, output_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_size))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3)))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.load(path_data + 'y_train.npy')\n",
    "labels_test = np.load(path_data + 'y_test.npy')\n",
    "labels_val = np.load(path_data + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = np.ceil(43104 // batch_size + 1)\n",
    "steps_va = np.ceil(9237 // batch_size + 1)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [0.008220546006904953, 0.09034255245887919]\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = galaxy_cnn((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_1', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(generator(path_data + 'preprocess_img_train', labels_train, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        validation_data= generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size),\n",
    "        validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "# Evaluation over validation test\n",
    "evaluation = model.evaluate_generator(generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size), steps=steps)\n",
    "print('Evaluation:', evaluation)\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_1.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1348/1348 [==============================] - 254s 189ms/step - loss: 0.0231 - rmse: 0.1492 - val_loss: 0.0157 - val_rmse: 0.1249\n",
      "Epoch 2/50\n",
      "1348/1348 [==============================] - 242s 180ms/step - loss: 0.0141 - rmse: 0.1186 - val_loss: 0.0119 - val_rmse: 0.1089\n",
      "Epoch 3/50\n",
      "1348/1348 [==============================] - 243s 180ms/step - loss: 0.0121 - rmse: 0.1097 - val_loss: 0.0113 - val_rmse: 0.1062\n",
      "Epoch 4/50\n",
      "1348/1348 [==============================] - 243s 180ms/step - loss: 0.0112 - rmse: 0.1054 - val_loss: 0.0109 - val_rmse: 0.1041\n",
      "Epoch 5/50\n",
      "1348/1348 [==============================] - 243s 180ms/step - loss: 0.0105 - rmse: 0.1022 - val_loss: 0.0102 - val_rmse: 0.1008\n",
      "Epoch 6/50\n",
      "1348/1348 [==============================] - 239s 178ms/step - loss: 0.0100 - rmse: 0.0995 - val_loss: 0.0097 - val_rmse: 0.0984\n",
      "Epoch 7/50\n",
      "1348/1348 [==============================] - 246s 183ms/step - loss: 0.0096 - rmse: 0.0975 - val_loss: 0.0095 - val_rmse: 0.0972\n",
      "Epoch 8/50\n",
      "1348/1348 [==============================] - 235s 174ms/step - loss: 0.0092 - rmse: 0.0959 - val_loss: 0.0094 - val_rmse: 0.0968\n",
      "Epoch 9/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0090 - rmse: 0.0944 - val_loss: 0.0091 - val_rmse: 0.0952\n",
      "Epoch 10/50\n",
      "1348/1348 [==============================] - 236s 175ms/step - loss: 0.0088 - rmse: 0.0933 - val_loss: 0.0092 - val_rmse: 0.0957\n",
      "Epoch 11/50\n",
      "1348/1348 [==============================] - 262s 194ms/step - loss: 0.0086 - rmse: 0.0923 - val_loss: 0.0091 - val_rmse: 0.0949\n",
      "Epoch 12/50\n",
      "1348/1348 [==============================] - 239s 178ms/step - loss: 0.0083 - rmse: 0.0910 - val_loss: 0.0089 - val_rmse: 0.0940\n",
      "Epoch 13/50\n",
      "1348/1348 [==============================] - 241s 179ms/step - loss: 0.0082 - rmse: 0.0902 - val_loss: 0.0087 - val_rmse: 0.0931\n",
      "Epoch 14/50\n",
      "1348/1348 [==============================] - 237s 176ms/step - loss: 0.0080 - rmse: 0.0894 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 15/50\n",
      "1348/1348 [==============================] - 238s 176ms/step - loss: 0.0079 - rmse: 0.0885 - val_loss: 0.0087 - val_rmse: 0.0930\n",
      "Epoch 16/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0078 - rmse: 0.0879 - val_loss: 0.0088 - val_rmse: 0.0933\n",
      "Epoch 17/50\n",
      "1348/1348 [==============================] - 237s 176ms/step - loss: 0.0076 - rmse: 0.0871 - val_loss: 0.0088 - val_rmse: 0.0933\n",
      "Epoch 18/50\n",
      "1348/1348 [==============================] - 240s 178ms/step - loss: 0.0075 - rmse: 0.0865 - val_loss: 0.0087 - val_rmse: 0.0928\n",
      "Epoch 19/50\n",
      "1348/1348 [==============================] - 239s 177ms/step - loss: 0.0074 - rmse: 0.0858 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 20/50\n",
      "1348/1348 [==============================] - 233s 173ms/step - loss: 0.0073 - rmse: 0.0853 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 21/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0072 - rmse: 0.0847 - val_loss: 0.0084 - val_rmse: 0.0911\n",
      "Epoch 22/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0071 - rmse: 0.0840 - val_loss: 0.0085 - val_rmse: 0.0920\n",
      "Epoch 23/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0070 - rmse: 0.0836 - val_loss: 0.0085 - val_rmse: 0.0920\n",
      "Epoch 24/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0069 - rmse: 0.0830 - val_loss: 0.0084 - val_rmse: 0.0916\n",
      "Epoch 25/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0069 - rmse: 0.0826 - val_loss: 0.0085 - val_rmse: 0.0917\n",
      "Epoch 26/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0067 - rmse: 0.0817 - val_loss: 0.0084 - val_rmse: 0.0915\n",
      "Epoch 27/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0067 - rmse: 0.0815 - val_loss: 0.0084 - val_rmse: 0.0911\n",
      "Epoch 28/50\n",
      "1348/1348 [==============================] - 235s 174ms/step - loss: 0.0066 - rmse: 0.0810 - val_loss: 0.0083 - val_rmse: 0.0910\n",
      "Epoch 29/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0065 - rmse: 0.0805 - val_loss: 0.0084 - val_rmse: 0.0914\n",
      "Epoch 30/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0064 - rmse: 0.0799 - val_loss: 0.0085 - val_rmse: 0.0916\n",
      "Epoch 31/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0064 - rmse: 0.0796 - val_loss: 0.0085 - val_rmse: 0.0917\n",
      "Epoch 32/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0063 - rmse: 0.0792 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 33/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0062 - rmse: 0.0786 - val_loss: 0.0086 - val_rmse: 0.0925\n",
      "Epoch 34/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0061 - rmse: 0.0781 - val_loss: 0.0090 - val_rmse: 0.0945\n",
      "Epoch 35/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0061 - rmse: 0.0779 - val_loss: 0.0090 - val_rmse: 0.0942\n",
      "Epoch 36/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0060 - rmse: 0.0772 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 37/50\n",
      "1348/1348 [==============================] - 233s 172ms/step - loss: 0.0060 - rmse: 0.0769 - val_loss: 0.0091 - val_rmse: 0.0948\n",
      "Epoch 38/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0059 - rmse: 0.0768 - val_loss: 0.0088 - val_rmse: 0.0933\n",
      "Epoch 39/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0058 - rmse: 0.0760 - val_loss: 0.0088 - val_rmse: 0.0936\n",
      "Epoch 40/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0058 - rmse: 0.0762 - val_loss: 0.0090 - val_rmse: 0.0944\n",
      "Epoch 41/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0058 - rmse: 0.0757 - val_loss: 0.0088 - val_rmse: 0.0935\n",
      "Epoch 42/50\n",
      "1348/1348 [==============================] - 233s 173ms/step - loss: 0.0057 - rmse: 0.0751 - val_loss: 0.0087 - val_rmse: 0.0930\n",
      "Epoch 43/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0056 - rmse: 0.0746 - val_loss: 0.0086 - val_rmse: 0.0924\n",
      "Epoch 44/50\n",
      "1348/1348 [==============================] - 240s 178ms/step - loss: 0.0056 - rmse: 0.0744 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 45/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0055 - rmse: 0.0740 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 46/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0055 - rmse: 0.0737 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 47/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0054 - rmse: 0.0734 - val_loss: 0.0084 - val_rmse: 0.0915\n",
      "Epoch 48/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0054 - rmse: 0.0732 - val_loss: 0.0086 - val_rmse: 0.0924\n",
      "Epoch 49/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0053 - rmse: 0.0729 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 50/50\n",
      "1348/1348 [==============================] - 233s 173ms/step - loss: 0.0053 - rmse: 0.0726 - val_loss: 0.0084 - val_rmse: 0.0911\n",
      "Evaluation: [0.008391103329779522, 0.0912702066842515]\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = galaxy_cnn_2((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_2', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(generator(path_data + 'preprocess_img_train', labels_train, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        validation_data= generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size),\n",
    "        validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "# Evaluation over validation test\n",
    "evaluation = model.evaluate_generator(generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size), steps=steps)\n",
    "print('Evaluation:', evaluation)\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_2.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_test = np.load(path_data + 'y_train_test.npy')\n",
    "labels_val = np.load(path_data + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100122', 0.7388319999999999, 0.238159, 0.023009, 0.0, 0.238159,\n",
       "       0.0, 0.238159, 0.0, 0.238159, 0.0, 0.0, 0.238159, 0.0, 0.19793,\n",
       "       0.80207, 0.066806667, 0.663691308, 0.008334764, 0.0, 0.0,\n",
       "       0.0494825, 0.098965, 0.0494825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = np.ceil(52341 // batch_size + 1)\n",
    "steps_va = np.ceil(9237 // batch_size + 1)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/50\n",
      "1636/1636 [==============================] - 182s 111ms/step - loss: 0.0225 - rmse: 0.1475 - val_loss: 0.0159 - val_rmse: 0.1259\n",
      "Epoch 2/50\n",
      "1636/1636 [==============================] - 179s 109ms/step - loss: 0.0153 - rmse: 0.1234 - val_loss: 0.0126 - val_rmse: 0.1119\n",
      "Epoch 3/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0131 - rmse: 0.1143 - val_loss: 0.0116 - val_rmse: 0.1073\n",
      "Epoch 4/50\n",
      "1636/1636 [==============================] - 179s 109ms/step - loss: 0.0121 - rmse: 0.1096 - val_loss: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 5/50\n",
      "1636/1636 [==============================] - 179s 110ms/step - loss: 0.0113 - rmse: 0.1061 - val_loss: 0.0101 - val_rmse: 0.1004\n",
      "Epoch 6/50\n",
      "1636/1636 [==============================] - 179s 109ms/step - loss: 0.0108 - rmse: 0.1035 - val_loss: 0.0099 - val_rmse: 0.0991\n",
      "Epoch 7/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0103 - rmse: 0.1014 - val_loss: 0.0095 - val_rmse: 0.0969\n",
      "Epoch 8/50\n",
      "1636/1636 [==============================] - 173s 106ms/step - loss: 0.0100 - rmse: 0.0997 - val_loss: 0.0094 - val_rmse: 0.0966\n",
      "Epoch 9/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0097 - rmse: 0.0982 - val_loss: 0.0091 - val_rmse: 0.0950\n",
      "Epoch 10/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0094 - rmse: 0.0966 - val_loss: 0.0093 - val_rmse: 0.0959\n",
      "Epoch 11/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0091 - rmse: 0.0953 - val_loss: 0.0089 - val_rmse: 0.0938\n",
      "Epoch 12/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0089 - rmse: 0.0942 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 13/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0087 - rmse: 0.0931 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 14/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0086 - rmse: 0.0922 - val_loss: 0.0085 - val_rmse: 0.0919\n",
      "Epoch 15/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0084 - rmse: 0.0913 - val_loss: 0.0084 - val_rmse: 0.0912\n",
      "Epoch 16/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0082 - rmse: 0.0904 - val_loss: 0.0083 - val_rmse: 0.0908\n",
      "Epoch 17/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0081 - rmse: 0.0896 - val_loss: 0.0082 - val_rmse: 0.0899\n",
      "Epoch 18/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0079 - rmse: 0.0889 - val_loss: 0.0081 - val_rmse: 0.0899\n",
      "Epoch 19/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0078 - rmse: 0.0882 - val_loss: 0.0080 - val_rmse: 0.0893\n",
      "Epoch 20/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0077 - rmse: 0.0875 - val_loss: 0.0081 - val_rmse: 0.0896\n",
      "Epoch 21/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0076 - rmse: 0.0870 - val_loss: 0.0080 - val_rmse: 0.0889\n",
      "Epoch 22/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0075 - rmse: 0.0865 - val_loss: 0.0081 - val_rmse: 0.0894\n",
      "Epoch 23/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0074 - rmse: 0.0859 - val_loss: 0.0078 - val_rmse: 0.0882\n",
      "Epoch 24/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0073 - rmse: 0.0853 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 25/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0072 - rmse: 0.0847 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 26/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0071 - rmse: 0.0843 - val_loss: 0.0078 - val_rmse: 0.0880\n",
      "Epoch 27/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0071 - rmse: 0.0838 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 28/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0070 - rmse: 0.0832 - val_loss: 0.0080 - val_rmse: 0.0889\n",
      "Epoch 29/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0069 - rmse: 0.0828 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 30/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0068 - rmse: 0.0824 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 31/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0067 - rmse: 0.0817 - val_loss: 0.0080 - val_rmse: 0.0889\n",
      "Epoch 32/50\n",
      "1636/1636 [==============================] - 175s 107ms/step - loss: 0.0067 - rmse: 0.0814 - val_loss: 0.0078 - val_rmse: 0.0881\n",
      "Epoch 33/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0066 - rmse: 0.0808 - val_loss: 0.0078 - val_rmse: 0.0881\n",
      "Epoch 34/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0065 - rmse: 0.0804 - val_loss: 0.0078 - val_rmse: 0.0879\n",
      "Epoch 35/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0064 - rmse: 0.0800 - val_loss: 0.0079 - val_rmse: 0.0885\n",
      "Epoch 36/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0064 - rmse: 0.0797 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 37/50\n",
      "1636/1636 [==============================] - 180s 110ms/step - loss: 0.0063 - rmse: 0.0792 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 38/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0063 - rmse: 0.0788 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 39/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0062 - rmse: 0.0785 - val_loss: 0.0078 - val_rmse: 0.0882\n",
      "Epoch 40/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0061 - rmse: 0.0781 - val_loss: 0.0079 - val_rmse: 0.0883\n",
      "Epoch 41/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0061 - rmse: 0.0777 - val_loss: 0.0078 - val_rmse: 0.0882\n",
      "Epoch 42/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0060 - rmse: 0.0775 - val_loss: 0.0079 - val_rmse: 0.0883\n",
      "Epoch 43/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0060 - rmse: 0.0771 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 44/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0059 - rmse: 0.0769 - val_loss: 0.0079 - val_rmse: 0.0883\n",
      "Epoch 45/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0058 - rmse: 0.0762 - val_loss: 0.0080 - val_rmse: 0.0894\n",
      "Epoch 46/50\n",
      "1636/1636 [==============================] - 173s 106ms/step - loss: 0.0058 - rmse: 0.0759 - val_loss: 0.0079 - val_rmse: 0.0887\n",
      "Epoch 47/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0058 - rmse: 0.0756 - val_loss: 0.0080 - val_rmse: 0.0891\n",
      "Epoch 48/50\n",
      "1636/1636 [==============================] - 176s 108ms/step - loss: 0.0057 - rmse: 0.0755 - val_loss: 0.0079 - val_rmse: 0.0887\n",
      "Epoch 49/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0056 - rmse: 0.0749 - val_loss: 0.0079 - val_rmse: 0.0888\n",
      "Epoch 50/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0056 - rmse: 0.0747 - val_loss: 0.0079 - val_rmse: 0.0886\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = galaxy_cnn((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_1_train_test', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(generator(path_data + 'train_test_img', labels_train_test, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        validation_data= generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size, val=True),\n",
    "        validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_1_train_test.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1348/1348 [==============================] - 235s 174ms/step - loss: 0.0190 - rmse: 0.1366 - val_loss: 0.0134 - val_rmse: 0.1155\n",
      "Epoch 2/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0131 - rmse: 0.1140 - val_loss: 0.0111 - val_rmse: 0.1052\n",
      "Epoch 3/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0115 - rmse: 0.1072 - val_loss: 0.0109 - val_rmse: 0.1041\n",
      "Epoch 4/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0109 - rmse: 0.1039 - val_loss: 0.0103 - val_rmse: 0.1012\n",
      "Epoch 5/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0102 - rmse: 0.1008 - val_loss: 0.0101 - val_rmse: 0.1000\n",
      "Epoch 6/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0098 - rmse: 0.0985 - val_loss: 0.0096 - val_rmse: 0.0977\n",
      "Epoch 7/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0095 - rmse: 0.0970 - val_loss: 0.0096 - val_rmse: 0.0975\n",
      "Epoch 8/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0092 - rmse: 0.0957 - val_loss: 0.0092 - val_rmse: 0.0954\n",
      "Epoch 9/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0090 - rmse: 0.0944 - val_loss: 0.0093 - val_rmse: 0.0961\n",
      "Epoch 10/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0088 - rmse: 0.0934 - val_loss: 0.0090 - val_rmse: 0.0945\n",
      "Epoch 11/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0086 - rmse: 0.0926 - val_loss: 0.0088 - val_rmse: 0.0935\n",
      "Epoch 12/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0084 - rmse: 0.0913 - val_loss: 0.0089 - val_rmse: 0.0941\n",
      "Epoch 13/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0083 - rmse: 0.0906 - val_loss: 0.0091 - val_rmse: 0.0950\n",
      "Epoch 14/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0081 - rmse: 0.0899 - val_loss: 0.0089 - val_rmse: 0.0942\n",
      "Epoch 15/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0080 - rmse: 0.0890 - val_loss: 0.0089 - val_rmse: 0.0941\n",
      "Epoch 16/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0079 - rmse: 0.0885 - val_loss: 0.0087 - val_rmse: 0.0928\n",
      "Epoch 17/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0078 - rmse: 0.0880 - val_loss: 0.0085 - val_rmse: 0.0919\n",
      "Epoch 18/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0076 - rmse: 0.0870 - val_loss: 0.0087 - val_rmse: 0.0928\n",
      "Epoch 19/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0075 - rmse: 0.0863 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 20/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0074 - rmse: 0.0859 - val_loss: 0.0085 - val_rmse: 0.0919\n",
      "Epoch 21/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0073 - rmse: 0.0854 - val_loss: 0.0084 - val_rmse: 0.0914\n",
      "Epoch 22/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0073 - rmse: 0.0850 - val_loss: 0.0086 - val_rmse: 0.0921\n",
      "Epoch 23/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0072 - rmse: 0.0845 - val_loss: 0.0089 - val_rmse: 0.0938\n",
      "Epoch 24/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0071 - rmse: 0.0840 - val_loss: 0.0090 - val_rmse: 0.0943\n",
      "Epoch 25/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0070 - rmse: 0.0834 - val_loss: 0.0087 - val_rmse: 0.0929\n",
      "Epoch 26/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0069 - rmse: 0.0830 - val_loss: 0.0084 - val_rmse: 0.0915\n",
      "Epoch 27/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0068 - rmse: 0.0825 - val_loss: 0.0085 - val_rmse: 0.0920\n",
      "Epoch 28/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0068 - rmse: 0.0821 - val_loss: 0.0084 - val_rmse: 0.0912\n",
      "Epoch 29/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0067 - rmse: 0.0815 - val_loss: 0.0085 - val_rmse: 0.0917\n",
      "Epoch 30/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0066 - rmse: 0.0811 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 31/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0066 - rmse: 0.0810 - val_loss: 0.0084 - val_rmse: 0.0914\n",
      "Epoch 32/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0065 - rmse: 0.0803 - val_loss: 0.0084 - val_rmse: 0.0912\n",
      "Epoch 33/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0064 - rmse: 0.0800 - val_loss: 0.0087 - val_rmse: 0.0929\n",
      "Epoch 34/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0064 - rmse: 0.0796 - val_loss: 0.0086 - val_rmse: 0.0924\n",
      "Epoch 35/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0063 - rmse: 0.0790 - val_loss: 0.0088 - val_rmse: 0.0936\n",
      "Epoch 36/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0062 - rmse: 0.0786 - val_loss: 0.0087 - val_rmse: 0.0931\n",
      "Epoch 37/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0062 - rmse: 0.0785 - val_loss: 0.0087 - val_rmse: 0.0927\n",
      "Epoch 38/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0061 - rmse: 0.0782 - val_loss: 0.0088 - val_rmse: 0.0933\n",
      "Epoch 39/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0060 - rmse: 0.0775 - val_loss: 0.0085 - val_rmse: 0.0921\n",
      "Epoch 40/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0060 - rmse: 0.0773 - val_loss: 0.0084 - val_rmse: 0.0916\n",
      "Epoch 41/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0059 - rmse: 0.0769 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 42/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0059 - rmse: 0.0767 - val_loss: 0.0083 - val_rmse: 0.0909\n",
      "Epoch 43/50\n",
      "1348/1348 [==============================] - 231s 171ms/step - loss: 0.0059 - rmse: 0.0764 - val_loss: 0.0085 - val_rmse: 0.0916\n",
      "Epoch 44/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0058 - rmse: 0.0760 - val_loss: 0.0084 - val_rmse: 0.0912\n",
      "Epoch 45/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0058 - rmse: 0.0758 - val_loss: 0.0084 - val_rmse: 0.0914\n",
      "Epoch 46/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0057 - rmse: 0.0756 - val_loss: 0.0083 - val_rmse: 0.0907\n",
      "Epoch 47/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0057 - rmse: 0.0754 - val_loss: 0.0083 - val_rmse: 0.0910\n",
      "Epoch 48/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0057 - rmse: 0.0750 - val_loss: 0.0084 - val_rmse: 0.0915\n",
      "Epoch 49/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0056 - rmse: 0.0746 - val_loss: 0.0085 - val_rmse: 0.0917\n",
      "Epoch 50/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0056 - rmse: 0.0744 - val_loss: 0.0085 - val_rmse: 0.0919\n",
      "Evaluation: [0.008414974405298497, 0.09142655692787097]\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = galaxy_cnn_2((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_2_none', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(generator(path_data + 'preprocess_img_train', labels_train, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        validation_data= generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size),\n",
    "        validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "# Evaluation over validation test\n",
    "evaluation = model.evaluate_generator(generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size), steps=steps)\n",
    "print('Evaluation:', evaluation)\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_2_none.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all_data = np.load(path_data + 'y_all_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61578, 38)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = np.ceil(61578 // batch_size + 1)\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1925/1925 [==============================] - 189s 98ms/step - loss: 0.0217 - rmse: 0.1450\n",
      "Epoch 2/25\n",
      "1925/1925 [==============================] - 189s 98ms/step - loss: 0.0146 - rmse: 0.1204\n",
      "Epoch 3/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0125 - rmse: 0.1117\n",
      "Epoch 4/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0115 - rmse: 0.1069\n",
      "Epoch 5/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0108 - rmse: 0.1036\n",
      "Epoch 6/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0103 - rmse: 0.1011\n",
      "Epoch 7/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0098 - rmse: 0.0989\n",
      "Epoch 8/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0095 - rmse: 0.0973\n",
      "Epoch 9/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0092 - rmse: 0.0954\n",
      "Epoch 10/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0089 - rmse: 0.0940\n",
      "Epoch 11/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0086 - rmse: 0.0927\n",
      "Epoch 12/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0084 - rmse: 0.0914\n",
      "Epoch 13/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0082 - rmse: 0.0904\n",
      "Epoch 14/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0081 - rmse: 0.0895\n",
      "Epoch 15/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0079 - rmse: 0.0886\n",
      "Epoch 16/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0077 - rmse: 0.0877\n",
      "Epoch 17/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0076 - rmse: 0.0869\n",
      "Epoch 18/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0075 - rmse: 0.0861\n",
      "Epoch 19/25\n",
      "1925/1925 [==============================] - 186s 97ms/step - loss: 0.0073 - rmse: 0.0855\n",
      "Epoch 20/25\n",
      "1925/1925 [==============================] - 192s 100ms/step - loss: 0.0072 - rmse: 0.0848\n",
      "Epoch 21/25\n",
      "1925/1925 [==============================] - 192s 100ms/step - loss: 0.0071 - rmse: 0.0842\n",
      "Epoch 22/25\n",
      "1925/1925 [==============================] - 192s 100ms/step - loss: 0.0070 - rmse: 0.0835 - loss: 0.0070 - rmse\n",
      "Epoch 23/25\n",
      "1925/1925 [==============================] - 192s 100ms/step - loss: 0.0069 - rmse: 0.0831\n",
      "Epoch 24/25\n",
      "1925/1925 [==============================] - 192s 100ms/step - loss: 0.0068 - rmse: 0.0824\n",
      "Epoch 25/25\n",
      "1925/1925 [==============================] - 192s 100ms/step - loss: 0.0067 - rmse: 0.0819\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = galaxy_cnn((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_1_all_data', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(generator(path_data + 'train_test_img', labels_train_test, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        callbacks=[tbCallBack])\n",
    "\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_1_all_data.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv(path_data + 'all_zeros_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_test_sub = test_sub['GalaxyID'].apply(lambda x: str(x) + '.jpg').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = galaxy_cnn((160, 160, 3), 37)\n",
    "model.load_weights(path_data + 'weights/' + 'model_1_train_test.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_sub = 32\n",
    "steps_sub = np.ceil(79975 // batch_size_sub + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 698s 279ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(generator_predictions(path_data + 'sub_test_img', name_test_sub, batch_size=batch_size_sub), steps=steps_sub, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_sub.copy()\n",
    "results.head()\n",
    "columns = results.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in range(predictions.shape[1]):\n",
    "    column = columns[count]\n",
    "    results[column] = predictions[:, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>0.346925</td>\n",
       "      <td>0.643762</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>0.044182</td>\n",
       "      <td>0.603001</td>\n",
       "      <td>0.200188</td>\n",
       "      <td>0.407515</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.449610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.106377</td>\n",
       "      <td>0.060244</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.057141</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.109736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100037</td>\n",
       "      <td>0.414265</td>\n",
       "      <td>0.586715</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.078817</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.064192</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.059729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355658</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.010653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042</td>\n",
       "      <td>0.647536</td>\n",
       "      <td>0.339018</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>0.233329</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>0.022397</td>\n",
       "      <td>0.079855</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.084502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143508</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.014631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100052</td>\n",
       "      <td>0.546672</td>\n",
       "      <td>0.427690</td>\n",
       "      <td>0.032136</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.417123</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.402660</td>\n",
       "      <td>0.046020</td>\n",
       "      <td>0.381574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.030919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100056</td>\n",
       "      <td>0.214191</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.759802</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520035</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100018  0.346925  0.643762  0.011634  0.044182  0.603001  0.200188   \n",
       "1    100037  0.414265  0.586715  0.006081  0.514483  0.078817  0.009039   \n",
       "2    100042  0.647536  0.339018  0.012971  0.233329  0.106007  0.022397   \n",
       "3    100052  0.546672  0.427690  0.032136  0.004860  0.417123  0.010465   \n",
       "4    100056  0.214191  0.788704  0.003178  0.759802  0.018314  0.002850   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.407515  0.183076  0.449610    ...      0.006868   0.106377   0.060244   \n",
       "1  0.064192  0.016148  0.059729    ...      0.355658   0.009420   0.003744   \n",
       "2  0.079855  0.023471  0.084502    ...      0.143508   0.010715   0.005235   \n",
       "3  0.402660  0.046020  0.381574    ...      0.000189   0.024307   0.012805   \n",
       "4  0.015672  0.006010  0.011150    ...      0.520035   0.002748   0.001443   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.019532   0.005925   0.057141   0.003561   0.001952   0.003695   0.109736  \n",
       "1   0.002091   0.000113   0.002882   0.000022   0.000031   0.000076   0.010653  \n",
       "2   0.004539   0.000299   0.004889   0.000026   0.000031   0.000169   0.014631  \n",
       "3   0.004848   0.002994   0.005092   0.000856   0.000592   0.002663   0.030919  \n",
       "4   0.000921   0.000014   0.001508   0.000004   0.000008   0.000009   0.002709  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results.to_csv(path_data + 'results_train_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv(path_data + 'all_zeros_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_test_sub = test_sub['GalaxyID'].apply(lambda x: str(x) + '.jpg').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "epochs = 25\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = galaxy_cnn((160, 160, 3), 37)\n",
    "model.load_weights(path_data + 'weights/' + 'model_1_all_data.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_sub = 32\n",
    "steps_sub = np.ceil(79975 // batch_size_sub + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 94s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(generator_predictions(path_data + 'sub_test_img', name_test_sub, batch_size=batch_size_sub), steps=steps_sub, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_sub.copy()\n",
    "results.head()\n",
    "columns = results.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in range(predictions.shape[1]):\n",
    "    column = columns[count]\n",
    "    results[column] = predictions[:, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>0.498929</td>\n",
       "      <td>0.484521</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.029538</td>\n",
       "      <td>0.457886</td>\n",
       "      <td>0.121249</td>\n",
       "      <td>0.337303</td>\n",
       "      <td>0.152857</td>\n",
       "      <td>0.308163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.093830</td>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.040953</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.101939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100037</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.544365</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.399661</td>\n",
       "      <td>0.177579</td>\n",
       "      <td>0.034880</td>\n",
       "      <td>0.141534</td>\n",
       "      <td>0.063909</td>\n",
       "      <td>0.120789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>0.016574</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.044672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042</td>\n",
       "      <td>0.653650</td>\n",
       "      <td>0.330237</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.250757</td>\n",
       "      <td>0.082550</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>0.015416</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134382</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.010567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100052</td>\n",
       "      <td>0.546370</td>\n",
       "      <td>0.432853</td>\n",
       "      <td>0.026330</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.428913</td>\n",
       "      <td>0.026269</td>\n",
       "      <td>0.410655</td>\n",
       "      <td>0.097361</td>\n",
       "      <td>0.349402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.053577</td>\n",
       "      <td>0.032062</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.058519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100056</td>\n",
       "      <td>0.175571</td>\n",
       "      <td>0.821594</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.776542</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.030479</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.008859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100018  0.498929  0.484521  0.015520  0.029538  0.457886  0.121249   \n",
       "1    100037  0.444095  0.544365  0.016311  0.399661  0.177579  0.034880   \n",
       "2    100042  0.653650  0.330237  0.010269  0.250757  0.082550  0.014070   \n",
       "3    100052  0.546370  0.432853  0.026330  0.007645  0.428913  0.026269   \n",
       "4    100056  0.175571  0.821594  0.006239  0.776542  0.035632  0.008878   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.337303  0.152857  0.308163    ...      0.004015   0.093830   0.046974   \n",
       "1  0.141534  0.063909  0.120789    ...      0.309674   0.031725   0.016574   \n",
       "2  0.057086  0.015416  0.059824    ...      0.134382   0.007916   0.003082   \n",
       "3  0.410655  0.097361  0.349402    ...      0.000475   0.053577   0.032062   \n",
       "4  0.030479  0.017929  0.020094    ...      0.448413   0.007156   0.004766   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.013948   0.005331   0.040953   0.002538   0.001344   0.002983   0.101939  \n",
       "1   0.011426   0.001322   0.013688   0.000345   0.000444   0.000825   0.044672  \n",
       "2   0.002554   0.000154   0.002643   0.000014   0.000028   0.000151   0.010567  \n",
       "3   0.012592   0.008409   0.018628   0.003103   0.001431   0.003497   0.058519  \n",
       "4   0.004248   0.000101   0.007112   0.000071   0.000133   0.000167   0.008859  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results.to_csv(path_data + 'results_all_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
