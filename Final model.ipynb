{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import helper as hp\n",
    "from keras.models import load_model\n",
    "from keras import optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.load(path_data + 'y_train.npy')\n",
    "labels_test = np.load(path_data + 'y_test.npy')\n",
    "labels_val = np.load(path_data + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = np.ceil(43104 // batch_size + 1)\n",
    "steps_va = np.ceil(9237 // batch_size + 1)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [0.008220546006904953, 0.09034255245887919]\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = hp.galaxy_cnn((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_1', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(hp.generator(path_data + 'preprocess_img_train', labels_train, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        validation_data= hp.generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size, val=True),\n",
    "        validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "# Evaluation over validation test\n",
    "evaluation = model.evaluate_generator(hp.generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size, val=True), steps=steps)\n",
    "print('Evaluation:', evaluation)\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_1.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1348/1348 [==============================] - 254s 189ms/step - loss: 0.0231 - rmse: 0.1492 - val_loss: 0.0157 - val_rmse: 0.1249\n",
      "Epoch 2/50\n",
      "1348/1348 [==============================] - 242s 180ms/step - loss: 0.0141 - rmse: 0.1186 - val_loss: 0.0119 - val_rmse: 0.1089\n",
      "Epoch 3/50\n",
      "1348/1348 [==============================] - 243s 180ms/step - loss: 0.0121 - rmse: 0.1097 - val_loss: 0.0113 - val_rmse: 0.1062\n",
      "Epoch 4/50\n",
      "1348/1348 [==============================] - 243s 180ms/step - loss: 0.0112 - rmse: 0.1054 - val_loss: 0.0109 - val_rmse: 0.1041\n",
      "Epoch 5/50\n",
      "1348/1348 [==============================] - 243s 180ms/step - loss: 0.0105 - rmse: 0.1022 - val_loss: 0.0102 - val_rmse: 0.1008\n",
      "Epoch 6/50\n",
      "1348/1348 [==============================] - 239s 178ms/step - loss: 0.0100 - rmse: 0.0995 - val_loss: 0.0097 - val_rmse: 0.0984\n",
      "Epoch 7/50\n",
      "1348/1348 [==============================] - 246s 183ms/step - loss: 0.0096 - rmse: 0.0975 - val_loss: 0.0095 - val_rmse: 0.0972\n",
      "Epoch 8/50\n",
      "1348/1348 [==============================] - 235s 174ms/step - loss: 0.0092 - rmse: 0.0959 - val_loss: 0.0094 - val_rmse: 0.0968\n",
      "Epoch 9/50\n",
      "1348/1348 [==============================] - 231s 172ms/step - loss: 0.0090 - rmse: 0.0944 - val_loss: 0.0091 - val_rmse: 0.0952\n",
      "Epoch 10/50\n",
      "1348/1348 [==============================] - 236s 175ms/step - loss: 0.0088 - rmse: 0.0933 - val_loss: 0.0092 - val_rmse: 0.0957\n",
      "Epoch 11/50\n",
      "1348/1348 [==============================] - 262s 194ms/step - loss: 0.0086 - rmse: 0.0923 - val_loss: 0.0091 - val_rmse: 0.0949\n",
      "Epoch 12/50\n",
      "1348/1348 [==============================] - 239s 178ms/step - loss: 0.0083 - rmse: 0.0910 - val_loss: 0.0089 - val_rmse: 0.0940\n",
      "Epoch 13/50\n",
      "1348/1348 [==============================] - 241s 179ms/step - loss: 0.0082 - rmse: 0.0902 - val_loss: 0.0087 - val_rmse: 0.0931\n",
      "Epoch 14/50\n",
      "1348/1348 [==============================] - 237s 176ms/step - loss: 0.0080 - rmse: 0.0894 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 15/50\n",
      "1348/1348 [==============================] - 238s 176ms/step - loss: 0.0079 - rmse: 0.0885 - val_loss: 0.0087 - val_rmse: 0.0930\n",
      "Epoch 16/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0078 - rmse: 0.0879 - val_loss: 0.0088 - val_rmse: 0.0933\n",
      "Epoch 17/50\n",
      "1348/1348 [==============================] - 237s 176ms/step - loss: 0.0076 - rmse: 0.0871 - val_loss: 0.0088 - val_rmse: 0.0933\n",
      "Epoch 18/50\n",
      "1348/1348 [==============================] - 240s 178ms/step - loss: 0.0075 - rmse: 0.0865 - val_loss: 0.0087 - val_rmse: 0.0928\n",
      "Epoch 19/50\n",
      "1348/1348 [==============================] - 239s 177ms/step - loss: 0.0074 - rmse: 0.0858 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 20/50\n",
      "1348/1348 [==============================] - 233s 173ms/step - loss: 0.0073 - rmse: 0.0853 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 21/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0072 - rmse: 0.0847 - val_loss: 0.0084 - val_rmse: 0.0911\n",
      "Epoch 22/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0071 - rmse: 0.0840 - val_loss: 0.0085 - val_rmse: 0.0920\n",
      "Epoch 23/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0070 - rmse: 0.0836 - val_loss: 0.0085 - val_rmse: 0.0920\n",
      "Epoch 24/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0069 - rmse: 0.0830 - val_loss: 0.0084 - val_rmse: 0.0916\n",
      "Epoch 25/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0069 - rmse: 0.0826 - val_loss: 0.0085 - val_rmse: 0.0917\n",
      "Epoch 26/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0067 - rmse: 0.0817 - val_loss: 0.0084 - val_rmse: 0.0915\n",
      "Epoch 27/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0067 - rmse: 0.0815 - val_loss: 0.0084 - val_rmse: 0.0911\n",
      "Epoch 28/50\n",
      "1348/1348 [==============================] - 235s 174ms/step - loss: 0.0066 - rmse: 0.0810 - val_loss: 0.0083 - val_rmse: 0.0910\n",
      "Epoch 29/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0065 - rmse: 0.0805 - val_loss: 0.0084 - val_rmse: 0.0914\n",
      "Epoch 30/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0064 - rmse: 0.0799 - val_loss: 0.0085 - val_rmse: 0.0916\n",
      "Epoch 31/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0064 - rmse: 0.0796 - val_loss: 0.0085 - val_rmse: 0.0917\n",
      "Epoch 32/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0063 - rmse: 0.0792 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 33/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0062 - rmse: 0.0786 - val_loss: 0.0086 - val_rmse: 0.0925\n",
      "Epoch 34/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0061 - rmse: 0.0781 - val_loss: 0.0090 - val_rmse: 0.0945\n",
      "Epoch 35/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0061 - rmse: 0.0779 - val_loss: 0.0090 - val_rmse: 0.0942\n",
      "Epoch 36/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0060 - rmse: 0.0772 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 37/50\n",
      "1348/1348 [==============================] - 233s 172ms/step - loss: 0.0060 - rmse: 0.0769 - val_loss: 0.0091 - val_rmse: 0.0948\n",
      "Epoch 38/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0059 - rmse: 0.0768 - val_loss: 0.0088 - val_rmse: 0.0933\n",
      "Epoch 39/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0058 - rmse: 0.0760 - val_loss: 0.0088 - val_rmse: 0.0936\n",
      "Epoch 40/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0058 - rmse: 0.0762 - val_loss: 0.0090 - val_rmse: 0.0944\n",
      "Epoch 41/50\n",
      "1348/1348 [==============================] - 232s 172ms/step - loss: 0.0058 - rmse: 0.0757 - val_loss: 0.0088 - val_rmse: 0.0935\n",
      "Epoch 42/50\n",
      "1348/1348 [==============================] - 233s 173ms/step - loss: 0.0057 - rmse: 0.0751 - val_loss: 0.0087 - val_rmse: 0.0930\n",
      "Epoch 43/50\n",
      "1348/1348 [==============================] - 234s 174ms/step - loss: 0.0056 - rmse: 0.0746 - val_loss: 0.0086 - val_rmse: 0.0924\n",
      "Epoch 44/50\n",
      "1348/1348 [==============================] - 240s 178ms/step - loss: 0.0056 - rmse: 0.0744 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 45/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0055 - rmse: 0.0740 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 46/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0055 - rmse: 0.0737 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 47/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0054 - rmse: 0.0734 - val_loss: 0.0084 - val_rmse: 0.0915\n",
      "Epoch 48/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0054 - rmse: 0.0732 - val_loss: 0.0086 - val_rmse: 0.0924\n",
      "Epoch 49/50\n",
      "1348/1348 [==============================] - 234s 173ms/step - loss: 0.0053 - rmse: 0.0729 - val_loss: 0.0085 - val_rmse: 0.0918\n",
      "Epoch 50/50\n",
      "1348/1348 [==============================] - 233s 173ms/step - loss: 0.0053 - rmse: 0.0726 - val_loss: 0.0084 - val_rmse: 0.0911\n",
      "Evaluation: [0.008391103329779522, 0.0912702066842515]\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = hp.galaxy_cnn_2((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_2', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(hp.generator(path_data + 'preprocess_img_train', labels_train, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        validation_data= hp.generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size, val=True),\n",
    "        validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "# Evaluation over validation test\n",
    "evaluation = model.evaluate_generator(hp.generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size, val=True), steps=steps)\n",
    "print('Evaluation:', evaluation)\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_2.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_test = np.load(path_data + 'y_train_test.npy')\n",
    "labels_val = np.load(path_data + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100122', 0.7388319999999999, 0.238159, 0.023009, 0.0, 0.238159,\n",
       "       0.0, 0.238159, 0.0, 0.238159, 0.0, 0.0, 0.238159, 0.0, 0.19793,\n",
       "       0.80207, 0.066806667, 0.663691308, 0.008334764, 0.0, 0.0,\n",
       "       0.0494825, 0.098965, 0.0494825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = np.ceil(52341 // batch_size + 1)\n",
    "steps_va = np.ceil(9237 // batch_size + 1)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/50\n",
      "1636/1636 [==============================] - 182s 111ms/step - loss: 0.0225 - rmse: 0.1475 - val_loss: 0.0159 - val_rmse: 0.1259\n",
      "Epoch 2/50\n",
      "1636/1636 [==============================] - 179s 109ms/step - loss: 0.0153 - rmse: 0.1234 - val_loss: 0.0126 - val_rmse: 0.1119\n",
      "Epoch 3/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0131 - rmse: 0.1143 - val_loss: 0.0116 - val_rmse: 0.1073\n",
      "Epoch 4/50\n",
      "1636/1636 [==============================] - 179s 109ms/step - loss: 0.0121 - rmse: 0.1096 - val_loss: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 5/50\n",
      "1636/1636 [==============================] - 179s 110ms/step - loss: 0.0113 - rmse: 0.1061 - val_loss: 0.0101 - val_rmse: 0.1004\n",
      "Epoch 6/50\n",
      "1636/1636 [==============================] - 179s 109ms/step - loss: 0.0108 - rmse: 0.1035 - val_loss: 0.0099 - val_rmse: 0.0991\n",
      "Epoch 7/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0103 - rmse: 0.1014 - val_loss: 0.0095 - val_rmse: 0.0969\n",
      "Epoch 8/50\n",
      "1636/1636 [==============================] - 173s 106ms/step - loss: 0.0100 - rmse: 0.0997 - val_loss: 0.0094 - val_rmse: 0.0966\n",
      "Epoch 9/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0097 - rmse: 0.0982 - val_loss: 0.0091 - val_rmse: 0.0950\n",
      "Epoch 10/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0094 - rmse: 0.0966 - val_loss: 0.0093 - val_rmse: 0.0959\n",
      "Epoch 11/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0091 - rmse: 0.0953 - val_loss: 0.0089 - val_rmse: 0.0938\n",
      "Epoch 12/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0089 - rmse: 0.0942 - val_loss: 0.0086 - val_rmse: 0.0926\n",
      "Epoch 13/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0087 - rmse: 0.0931 - val_loss: 0.0086 - val_rmse: 0.0923\n",
      "Epoch 14/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0086 - rmse: 0.0922 - val_loss: 0.0085 - val_rmse: 0.0919\n",
      "Epoch 15/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0084 - rmse: 0.0913 - val_loss: 0.0084 - val_rmse: 0.0912\n",
      "Epoch 16/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0082 - rmse: 0.0904 - val_loss: 0.0083 - val_rmse: 0.0908\n",
      "Epoch 17/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0081 - rmse: 0.0896 - val_loss: 0.0082 - val_rmse: 0.0899\n",
      "Epoch 18/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0079 - rmse: 0.0889 - val_loss: 0.0081 - val_rmse: 0.0899\n",
      "Epoch 19/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0078 - rmse: 0.0882 - val_loss: 0.0080 - val_rmse: 0.0893\n",
      "Epoch 20/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0077 - rmse: 0.0875 - val_loss: 0.0081 - val_rmse: 0.0896\n",
      "Epoch 21/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0076 - rmse: 0.0870 - val_loss: 0.0080 - val_rmse: 0.0889\n",
      "Epoch 22/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0075 - rmse: 0.0865 - val_loss: 0.0081 - val_rmse: 0.0894\n",
      "Epoch 23/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0074 - rmse: 0.0859 - val_loss: 0.0078 - val_rmse: 0.0882\n",
      "Epoch 24/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0073 - rmse: 0.0853 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 25/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0072 - rmse: 0.0847 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 26/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0071 - rmse: 0.0843 - val_loss: 0.0078 - val_rmse: 0.0880\n",
      "Epoch 27/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0071 - rmse: 0.0838 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 28/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0070 - rmse: 0.0832 - val_loss: 0.0080 - val_rmse: 0.0889\n",
      "Epoch 29/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0069 - rmse: 0.0828 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 30/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0068 - rmse: 0.0824 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 31/50\n",
      "1636/1636 [==============================] - 170s 104ms/step - loss: 0.0067 - rmse: 0.0817 - val_loss: 0.0080 - val_rmse: 0.0889\n",
      "Epoch 32/50\n",
      "1636/1636 [==============================] - 175s 107ms/step - loss: 0.0067 - rmse: 0.0814 - val_loss: 0.0078 - val_rmse: 0.0881\n",
      "Epoch 33/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0066 - rmse: 0.0808 - val_loss: 0.0078 - val_rmse: 0.0881\n",
      "Epoch 34/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0065 - rmse: 0.0804 - val_loss: 0.0078 - val_rmse: 0.0879\n",
      "Epoch 35/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0064 - rmse: 0.0800 - val_loss: 0.0079 - val_rmse: 0.0885\n",
      "Epoch 36/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0064 - rmse: 0.0797 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 37/50\n",
      "1636/1636 [==============================] - 180s 110ms/step - loss: 0.0063 - rmse: 0.0792 - val_loss: 0.0079 - val_rmse: 0.0886\n",
      "Epoch 38/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0063 - rmse: 0.0788 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 39/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0062 - rmse: 0.0785 - val_loss: 0.0078 - val_rmse: 0.0882\n",
      "Epoch 40/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0061 - rmse: 0.0781 - val_loss: 0.0079 - val_rmse: 0.0883\n",
      "Epoch 41/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0061 - rmse: 0.0777 - val_loss: 0.0078 - val_rmse: 0.0882\n",
      "Epoch 42/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0060 - rmse: 0.0775 - val_loss: 0.0079 - val_rmse: 0.0883\n",
      "Epoch 43/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0060 - rmse: 0.0771 - val_loss: 0.0079 - val_rmse: 0.0884\n",
      "Epoch 44/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0059 - rmse: 0.0769 - val_loss: 0.0079 - val_rmse: 0.0883\n",
      "Epoch 45/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0058 - rmse: 0.0762 - val_loss: 0.0080 - val_rmse: 0.0894\n",
      "Epoch 46/50\n",
      "1636/1636 [==============================] - 173s 106ms/step - loss: 0.0058 - rmse: 0.0759 - val_loss: 0.0079 - val_rmse: 0.0887\n",
      "Epoch 47/50\n",
      "1636/1636 [==============================] - 178s 109ms/step - loss: 0.0058 - rmse: 0.0756 - val_loss: 0.0080 - val_rmse: 0.0891\n",
      "Epoch 48/50\n",
      "1636/1636 [==============================] - 176s 108ms/step - loss: 0.0057 - rmse: 0.0755 - val_loss: 0.0079 - val_rmse: 0.0887\n",
      "Epoch 49/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0056 - rmse: 0.0749 - val_loss: 0.0079 - val_rmse: 0.0888\n",
      "Epoch 50/50\n",
      "1636/1636 [==============================] - 169s 103ms/step - loss: 0.0056 - rmse: 0.0747 - val_loss: 0.0079 - val_rmse: 0.0886\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = hp.galaxy_cnn((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph/model_1_train_test', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# Train the model\n",
    "model.fit_generator(hp.generator(path_data + 'train_test_img', labels_train_test, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs, \n",
    "        validation_data= hp.generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size, val=True),\n",
    "        validation_steps=steps_va, callbacks=[tbCallBack])\n",
    "\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_1_train_test.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all_data = np.load(path_data + 'y_all_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61578, 38)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = np.ceil(61578 // batch_size + 1)\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/25\n",
      "1925/1925 [==============================] - 163s 84ms/step - loss: 0.0211 - rmse: 0.1428\n",
      "Epoch 2/25\n",
      "1925/1925 [==============================] - 157s 81ms/step - loss: 0.0148 - rmse: 0.1212\n",
      "Epoch 3/25\n",
      "1925/1925 [==============================] - 156s 81ms/step - loss: 0.0126 - rmse: 0.1117\n",
      "Epoch 4/25\n",
      "1925/1925 [==============================] - 157s 82ms/step - loss: 0.0116 - rmse: 0.1075\n",
      "Epoch 5/25\n",
      "1925/1925 [==============================] - 160s 83ms/step - loss: 0.0110 - rmse: 0.1046\n",
      "Epoch 6/25\n",
      "1925/1925 [==============================] - 160s 83ms/step - loss: 0.0105 - rmse: 0.1021\n",
      "Epoch 7/25\n",
      "1925/1925 [==============================] - 160s 83ms/step - loss: 0.0101 - rmse: 0.1000\n",
      "Epoch 8/25\n",
      "1925/1925 [==============================] - 162s 84ms/step - loss: 0.0097 - rmse: 0.0981\n",
      "Epoch 9/25\n",
      "1925/1925 [==============================] - 162s 84ms/step - loss: 0.0094 - rmse: 0.0966\n",
      "Epoch 10/25\n",
      "1925/1925 [==============================] - 162s 84ms/step - loss: 0.0091 - rmse: 0.0949\n",
      "Epoch 11/25\n",
      "1925/1925 [==============================] - 163s 84ms/step - loss: 0.0088 - rmse: 0.0936\n",
      "Epoch 12/25\n",
      "1925/1925 [==============================] - 163s 85ms/step - loss: 0.0086 - rmse: 0.0923\n",
      "Epoch 13/25\n",
      "1925/1925 [==============================] - 163s 85ms/step - loss: 0.0083 - rmse: 0.0909\n",
      "Epoch 14/25\n",
      "1925/1925 [==============================] - 162s 84ms/step - loss: 0.0081 - rmse: 0.0898\n",
      "Epoch 15/25\n",
      "1925/1925 [==============================] - 160s 83ms/step - loss: 0.0079 - rmse: 0.0888\n",
      "Epoch 16/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0078 - rmse: 0.0878\n",
      "Epoch 17/25\n",
      "1925/1925 [==============================] - 157s 81ms/step - loss: 0.0076 - rmse: 0.0870\n",
      "Epoch 18/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0074 - rmse: 0.0860\n",
      "Epoch 19/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0073 - rmse: 0.0853\n",
      "Epoch 20/25\n",
      "1925/1925 [==============================] - 157s 82ms/step - loss: 0.0072 - rmse: 0.0845\n",
      "Epoch 21/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0071 - rmse: 0.0837\n",
      "Epoch 22/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0069 - rmse: 0.0829\n",
      "Epoch 23/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0068 - rmse: 0.0825\n",
      "Epoch 24/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0067 - rmse: 0.0817\n",
      "Epoch 25/25\n",
      "1925/1925 [==============================] - 158s 82ms/step - loss: 0.0066 - rmse: 0.0812\n"
     ]
    }
   ],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = hp.galaxy_cnn((160, 160, 3), 37)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "# Train the model\n",
    "model.fit_generator(hp.generator(path_data + 'all_data_img', labels_all_data, batch_size=batch_size), \n",
    "        steps_per_epoch=steps, \n",
    "        epochs=epochs)\n",
    "\n",
    "# Save model after training\n",
    "model.save(path_data + 'weights/model_1_all_data_2.h5')\n",
    "# Clear session to free memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv(path_data + 'all_zeros_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_test_sub = test_sub['GalaxyID'].apply(lambda x: str(x) + '.jpg').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = hp.galaxy_cnn((160, 160, 3), 37)\n",
    "model.load_weights(path_data + 'weights/' + 'model_1_train_test.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_sub = 32\n",
    "steps_sub = np.ceil(79975 // batch_size_sub + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 698s 279ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(hp.generator_predictions(path_data + 'sub_test_img', name_test_sub, batch_size=batch_size_sub), steps=steps_sub, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_sub.copy()\n",
    "results.head()\n",
    "columns = results.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in range(predictions.shape[1]):\n",
    "    column = columns[count]\n",
    "    results[column] = predictions[:, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>0.346925</td>\n",
       "      <td>0.643762</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>0.044182</td>\n",
       "      <td>0.603001</td>\n",
       "      <td>0.200188</td>\n",
       "      <td>0.407515</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.449610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.106377</td>\n",
       "      <td>0.060244</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.057141</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.109736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100037</td>\n",
       "      <td>0.414265</td>\n",
       "      <td>0.586715</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.078817</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.064192</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.059729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355658</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.010653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042</td>\n",
       "      <td>0.647536</td>\n",
       "      <td>0.339018</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>0.233329</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>0.022397</td>\n",
       "      <td>0.079855</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.084502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143508</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.014631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100052</td>\n",
       "      <td>0.546672</td>\n",
       "      <td>0.427690</td>\n",
       "      <td>0.032136</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.417123</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.402660</td>\n",
       "      <td>0.046020</td>\n",
       "      <td>0.381574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.030919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100056</td>\n",
       "      <td>0.214191</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.759802</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520035</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100018  0.346925  0.643762  0.011634  0.044182  0.603001  0.200188   \n",
       "1    100037  0.414265  0.586715  0.006081  0.514483  0.078817  0.009039   \n",
       "2    100042  0.647536  0.339018  0.012971  0.233329  0.106007  0.022397   \n",
       "3    100052  0.546672  0.427690  0.032136  0.004860  0.417123  0.010465   \n",
       "4    100056  0.214191  0.788704  0.003178  0.759802  0.018314  0.002850   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.407515  0.183076  0.449610    ...      0.006868   0.106377   0.060244   \n",
       "1  0.064192  0.016148  0.059729    ...      0.355658   0.009420   0.003744   \n",
       "2  0.079855  0.023471  0.084502    ...      0.143508   0.010715   0.005235   \n",
       "3  0.402660  0.046020  0.381574    ...      0.000189   0.024307   0.012805   \n",
       "4  0.015672  0.006010  0.011150    ...      0.520035   0.002748   0.001443   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.019532   0.005925   0.057141   0.003561   0.001952   0.003695   0.109736  \n",
       "1   0.002091   0.000113   0.002882   0.000022   0.000031   0.000076   0.010653  \n",
       "2   0.004539   0.000299   0.004889   0.000026   0.000031   0.000169   0.014631  \n",
       "3   0.004848   0.002994   0.005092   0.000856   0.000592   0.002663   0.030919  \n",
       "4   0.000921   0.000014   0.001508   0.000004   0.000008   0.000009   0.002709  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results.to_csv(path_data + 'results_train_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv(path_data + 'all_zeros_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_test_sub = test_sub['GalaxyID'].apply(lambda x: str(x) + '.jpg').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set architecture\n",
    "learning_rate = 0.0001\n",
    "epochs = 25\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "model = hp.galaxy_cnn((160, 160, 3), 37)\n",
    "model.load_weights(path_data + 'weights/' + 'model_1_all_data_2.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_sub = 32\n",
    "steps_sub = np.ceil(79975 // batch_size_sub + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 527s 211ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(hp.generator_predictions(path_data + 'sub_test_img', name_test_sub, batch_size=batch_size_sub), steps=steps_sub, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_sub.copy()\n",
    "results.head()\n",
    "columns = results.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in range(predictions.shape[1]):\n",
    "    column = columns[count]\n",
    "    results[column] = predictions[:, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>0.413735</td>\n",
       "      <td>0.578915</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.547188</td>\n",
       "      <td>0.146427</td>\n",
       "      <td>0.404314</td>\n",
       "      <td>0.289031</td>\n",
       "      <td>0.269168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.156481</td>\n",
       "      <td>0.101055</td>\n",
       "      <td>0.058796</td>\n",
       "      <td>0.015295</td>\n",
       "      <td>0.123759</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>0.143571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100037</td>\n",
       "      <td>0.460871</td>\n",
       "      <td>0.555638</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.407864</td>\n",
       "      <td>0.101512</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.077785</td>\n",
       "      <td>0.019796</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.010142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042</td>\n",
       "      <td>0.661627</td>\n",
       "      <td>0.319158</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.190616</td>\n",
       "      <td>0.106425</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.085306</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157213</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.017031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100052</td>\n",
       "      <td>0.625350</td>\n",
       "      <td>0.351452</td>\n",
       "      <td>0.019919</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.343166</td>\n",
       "      <td>0.015532</td>\n",
       "      <td>0.311071</td>\n",
       "      <td>0.063154</td>\n",
       "      <td>0.271717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>0.018398</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.037713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100056</td>\n",
       "      <td>0.201026</td>\n",
       "      <td>0.781412</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.766965</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.013671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628588</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.004976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100018  0.413735  0.578915  0.016766  0.038258  0.547188  0.146427   \n",
       "1    100037  0.460871  0.555638  0.007446  0.407864  0.101512  0.012968   \n",
       "2    100042  0.661627  0.319158  0.009774  0.190616  0.106425  0.021125   \n",
       "3    100052  0.625350  0.351452  0.019919  0.010025  0.343166  0.015532   \n",
       "4    100056  0.201026  0.781412  0.003806  0.766965  0.020876  0.004683   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.404314  0.289031  0.269168    ...      0.005626   0.156481   0.101055   \n",
       "1  0.077785  0.019796  0.067530    ...      0.280255   0.008480   0.005142   \n",
       "2  0.085306  0.015869  0.087306    ...      0.157213   0.008626   0.004018   \n",
       "3  0.311071  0.063154  0.271717    ...      0.000196   0.027922   0.018398   \n",
       "4  0.020753  0.008532  0.013671    ...      0.628588   0.003312   0.002762   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.058796   0.015295   0.123759   0.007521   0.002920   0.005982   0.143571  \n",
       "1   0.003681   0.000606   0.005830   0.000056   0.000046   0.000077   0.010142  \n",
       "2   0.002878   0.000435   0.002703   0.000055   0.000060   0.000169   0.017031  \n",
       "3   0.007967   0.002798   0.008392   0.001926   0.000781   0.002859   0.037713  \n",
       "4   0.002896   0.000351   0.004005   0.000171   0.000167   0.000066   0.004976  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results.to_csv(path_data + 'results_all_dataset_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
