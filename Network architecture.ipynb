{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Reshape, Flatten, Dropout, Activation\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers, callbacks\n",
    "from skimage.transform import resize\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(np_img):\n",
    "    np_img = np_img / 255\n",
    "    return np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(path_images, labels, batch_size):\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        for i in range(batch_size):\n",
    "            # Read image\n",
    "            name_img = labels[count][0] + '.jpg'\n",
    "            img = imread(path_images + '/' + name_img)\n",
    "            \n",
    "            # Image preprocessing\n",
    "            img = preprocess_input(img)\n",
    "\n",
    "            label = labels[count][1:]\n",
    "\n",
    "            batch_features.append(img)\n",
    "            batch_labels.append(label)\n",
    "            count += 1\n",
    "            \n",
    "            # Restart counter when it has reached the size \n",
    "            # of the data set\n",
    "            if count == labels.shape[0] - 1:\n",
    "                count = 0\n",
    "                break\n",
    "            \n",
    "        yield np.array(batch_features), np.array(batch_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_predictions(path_images, list_names, batch_size):\n",
    "    size_list = list_names.shape[0] - 1\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        for i in range(batch_size):\n",
    "            # Read image\n",
    "            name_img = list_names[count]\n",
    "            img = imread(path_images + '/' + name_img)\n",
    "            \n",
    "            # Image preprocessing\n",
    "            img = preprocess_input(img)\n",
    "\n",
    "            batch_features.append(img)\n",
    "            \n",
    "            # Restart counter when it has reached the size \n",
    "            # of the data set\n",
    "            if count == size_list:\n",
    "                count = 0\n",
    "                yield np.array(batch_features)\n",
    "            count += 1\n",
    "            \n",
    "        yield np.array(batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_cnn(input_size, output_size, drop_out=False, batch_norm=False, dense_size=1024):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_size))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "    if drop_out:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "    if drop_out:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.load(path_data + 'y_train.npy')\n",
    "labels_test = np.load(path_data + 'y_test.npy')\n",
    "labels_val = np.load(path_data + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9237, 38)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_size = [512, 1024, 2048]\n",
    "drop_o = [False, True]\n",
    "batch_n = [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = 43104 // batch_size \n",
    "steps_va = 9237 // batch_size\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  model_Dense_2048_Drop_out_False_Batch_n_True\n",
      "Epoch 1/20\n",
      "1347/1347 [==============================] - 153s 114ms/step - loss: 0.0147 - rmse: 0.1201 - val_loss: 0.0131 - val_rmse: 0.1141\n",
      "Epoch 2/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0107 - rmse: 0.1031 - val_loss: 0.0119 - val_rmse: 0.1088\n",
      "Epoch 3/20\n",
      "1347/1347 [==============================] - 155s 115ms/step - loss: 0.0093 - rmse: 0.0960 - val_loss: 0.0112 - val_rmse: 0.1053\n",
      "Epoch 4/20\n",
      "1347/1347 [==============================] - 155s 115ms/step - loss: 0.0081 - rmse: 0.0896 - val_loss: 0.0109 - val_rmse: 0.1040\n",
      "Epoch 5/20\n",
      "1347/1347 [==============================] - 156s 116ms/step - loss: 0.0070 - rmse: 0.0832 - val_loss: 0.0109 - val_rmse: 0.1039\n",
      "Epoch 6/20\n",
      "1347/1347 [==============================] - 156s 116ms/step - loss: 0.0060 - rmse: 0.0774 - val_loss: 0.0114 - val_rmse: 0.1065\n",
      "Epoch 7/20\n",
      "1347/1347 [==============================] - 156s 116ms/step - loss: 0.0054 - rmse: 0.0736 - val_loss: 0.0120 - val_rmse: 0.1092\n",
      "Epoch 8/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0053 - rmse: 0.0725 - val_loss: 0.0112 - val_rmse: 0.1053\n",
      "Epoch 9/20\n",
      "1347/1347 [==============================] - 157s 116ms/step - loss: 0.0049 - rmse: 0.0699 - val_loss: 0.0102 - val_rmse: 0.1004\n",
      "Epoch 10/20\n",
      "1347/1347 [==============================] - 157s 116ms/step - loss: 0.0044 - rmse: 0.0660 - val_loss: 0.0109 - val_rmse: 0.1039\n",
      "Epoch 11/20\n",
      "1347/1347 [==============================] - 155s 115ms/step - loss: 0.0040 - rmse: 0.0629 - val_loss: 0.0111 - val_rmse: 0.1050\n",
      "Epoch 12/20\n",
      "1347/1347 [==============================] - 151s 112ms/step - loss: 0.0038 - rmse: 0.0615 - val_loss: 0.0114 - val_rmse: 0.1065\n",
      "Epoch 13/20\n",
      "1347/1347 [==============================] - 154s 115ms/step - loss: 0.0035 - rmse: 0.0593 - val_loss: 0.0132 - val_rmse: 0.1143\n",
      "Epoch 14/20\n",
      "1347/1347 [==============================] - 157s 116ms/step - loss: 0.0032 - rmse: 0.0565 - val_loss: 0.0106 - val_rmse: 0.1028\n",
      "Epoch 15/20\n",
      "1347/1347 [==============================] - 157s 117ms/step - loss: 0.0030 - rmse: 0.0544 - val_loss: 0.0111 - val_rmse: 0.1052\n",
      "Epoch 16/20\n",
      "1347/1347 [==============================] - 157s 116ms/step - loss: 0.0029 - rmse: 0.0533 - val_loss: 0.0114 - val_rmse: 0.1064\n",
      "Epoch 17/20\n",
      "1347/1347 [==============================] - 154s 114ms/step - loss: 0.0027 - rmse: 0.0515 - val_loss: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 18/20\n",
      "1347/1347 [==============================] - 147s 109ms/step - loss: 0.0025 - rmse: 0.0495 - val_loss: 0.0107 - val_rmse: 0.1030\n",
      "Epoch 19/20\n",
      "1347/1347 [==============================] - 149s 111ms/step - loss: 0.0023 - rmse: 0.0475 - val_loss: 0.0109 - val_rmse: 0.1043\n",
      "Epoch 20/20\n",
      "1347/1347 [==============================] - 153s 114ms/step - loss: 0.0022 - rmse: 0.0463 - val_loss: 0.0110 - val_rmse: 0.1046\n",
      "model_Dense_2048_Drop_out_False_Batch_n_True\n",
      "Evaluation: [0.010969073897548122, 0.10437506831011246]\n"
     ]
    }
   ],
   "source": [
    "for d_s in dense_size:\n",
    "    for d_o in drop_o:\n",
    "        for b_n in batch_n:\n",
    "            model_name = 'model' + '_Dense_'+ str(d_s) + '_Drop_out_' + str(d_o) + '_Batch_n_' + str(b_n)\n",
    "            print('Training model: ', model_name)\n",
    "            # Set architecture\n",
    "            opt = optimizers.Adam(lr=0.0001)\n",
    "            model = galaxy_cnn((160, 160, 3), 37, d_o, b_n, d_s)\n",
    "            model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "#             tbCallBack = callbacks.TensorBoard(log_dir=path_data + './Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "            # Train the model\n",
    "            model.fit_generator(generator(path_data + 'preprocess_img_train', labels_train, batch_size=batch_size), \n",
    "                    steps_per_epoch=steps, \n",
    "                    epochs=epochs, \n",
    "                    validation_data= generator(path_data + 'preprocess_img_val', labels_val, batch_size=batch_size),\n",
    "                    validation_steps=steps_va)\n",
    "            # Evaluation over validation test\n",
    "            evaluation = model.evaluate_generator(generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size), steps=steps)\n",
    "            print(model_name)\n",
    "            print('Evaluation:', evaluation)\n",
    "            # Save model after training\n",
    "            model.save(path_data + 'weights/' + model_name + '.h5')\n",
    "            # Clear session to free memory\n",
    "            K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model:  model_Dense_512_Drop_out_False_Batch_n_False\n",
      "Evaluating model:  model_Dense_512_Drop_out_False_Batch_n_True\n",
      "Evaluating model:  model_Dense_512_Drop_out_True_Batch_n_False\n",
      "Evaluating model:  model_Dense_512_Drop_out_True_Batch_n_True\n",
      "Evaluating model:  model_Dense_1024_Drop_out_False_Batch_n_False\n",
      "Evaluating model:  model_Dense_1024_Drop_out_False_Batch_n_True\n",
      "Evaluating model:  model_Dense_1024_Drop_out_True_Batch_n_False\n",
      "Evaluating model:  model_Dense_1024_Drop_out_True_Batch_n_True\n",
      "Evaluating model:  model_Dense_2048_Drop_out_False_Batch_n_False\n",
      "Evaluating model:  model_Dense_2048_Drop_out_False_Batch_n_True\n",
      "Evaluating model:  model_Dense_2048_Drop_out_True_Batch_n_False\n",
      "Evaluating model:  model_Dense_2048_Drop_out_True_Batch_n_True\n"
     ]
    }
   ],
   "source": [
    "model_names = []\n",
    "evaluations = []\n",
    "for d_s in dense_size:\n",
    "    for d_o in drop_o:\n",
    "        for b_n in batch_n:\n",
    "            model_name = 'model' + '_Dense_'+ str(d_s) + '_Drop_out_' + str(d_o) + '_Batch_n_' + str(b_n)\n",
    "            \n",
    "            print('Evaluating model: ', model_name)\n",
    "            \n",
    "            # Load the model\n",
    "            # Set architecture\n",
    "            opt = optimizers.Adam(lr=0.0001)\n",
    "            model = galaxy_cnn((160, 160, 3), 37, d_o, b_n, d_s)\n",
    "            model.load_weights(path_data + 'weights/' + model_name +'.h5')\n",
    "            model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "            \n",
    "            # Evaluate model\n",
    "            evaluation = model.evaluate_generator(generator(path_data + 'preprocess_img_test', labels_test, batch_size=batch_size), steps=steps)\n",
    "\n",
    "            model_names.append(model_name)\n",
    "            evaluations.append(evaluation)\n",
    "            \n",
    "            K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = np.array(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = evaluations[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = rmse_list.argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_Dense_2048_Drop_out_True_Batch_n_False 0.09997407958847312\n",
      "model_Dense_2048_Drop_out_True_Batch_n_True 0.1013503158260836\n",
      "model_Dense_1024_Drop_out_True_Batch_n_True 0.10138449899295766\n"
     ]
    }
   ],
   "source": [
    "for item in list_index[:3]:\n",
    "    print(model_names[item], rmse_list[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv(path_data + 'all_zeros_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_test_sub = test_sub['GalaxyID'].apply(lambda x: str(x) + '.jpg').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set best model for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.0001)\n",
    "model = galaxy_cnn((160, 160, 3), 37, True, False, 2048)\n",
    "model.load_weights(path_data + 'weights/' + 'model_Dense_2048_Drop_out_True_Batch_n_False.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_sub = 32\n",
    "steps_sub = np.ceil(79975 // batch_size_sub + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 92s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(generator_predictions(path_data + 'sub_test_img', name_test_sub, batch_size=batch_size_sub), steps=steps_sub, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_sub.copy()\n",
    "results.head()\n",
    "columns = prueba.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in range(predictions.shape[1]):\n",
    "    column = columns[count]\n",
    "    results[column] = predictions[:, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>0.535169</td>\n",
       "      <td>0.448261</td>\n",
       "      <td>0.019502</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.419044</td>\n",
       "      <td>0.078234</td>\n",
       "      <td>0.371073</td>\n",
       "      <td>0.100051</td>\n",
       "      <td>0.349070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.031145</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.025267</td>\n",
       "      <td>1.130747e-03</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.064111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100037</td>\n",
       "      <td>0.451488</td>\n",
       "      <td>0.546781</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.485883</td>\n",
       "      <td>0.070427</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.056207</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.051890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271759</td>\n",
       "      <td>0.010485</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>2.939095e-05</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.012347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042</td>\n",
       "      <td>0.665638</td>\n",
       "      <td>0.309743</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.247905</td>\n",
       "      <td>0.072442</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.052610</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.053177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117793</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>9.213272e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.006813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100052</td>\n",
       "      <td>0.565562</td>\n",
       "      <td>0.406442</td>\n",
       "      <td>0.029627</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.394116</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.386293</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.337812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.035641</td>\n",
       "      <td>0.018003</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>1.036999e-03</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.043148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100056</td>\n",
       "      <td>0.127365</td>\n",
       "      <td>0.869175</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.858430</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519266</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>8.200367e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100018  0.535169  0.448261  0.019502  0.030220  0.419044  0.078234   \n",
       "1    100037  0.451488  0.546781  0.005816  0.485883  0.070427  0.009963   \n",
       "2    100042  0.665638  0.309743  0.012054  0.247905  0.072442  0.010673   \n",
       "3    100052  0.565562  0.406442  0.029627  0.005225  0.394116  0.014635   \n",
       "4    100056  0.127365  0.869175  0.001181  0.858430  0.005488  0.001954   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.371073  0.100051  0.349070    ...      0.002883   0.053527   0.031145   \n",
       "1  0.056207  0.017074  0.051890    ...      0.271759   0.010485   0.005015   \n",
       "2  0.052610  0.013125  0.053177    ...      0.117793   0.004995   0.002808   \n",
       "3  0.386293  0.068376  0.337812    ...      0.000367   0.035641   0.018003   \n",
       "4  0.003685  0.001851  0.003085    ...      0.519266   0.000607   0.000419   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2     Class11.3  Class11.4  Class11.5  \\\n",
       "0   0.012281   0.004580   0.025267  1.130747e-03   0.000689   0.001644   \n",
       "1   0.001607   0.000150   0.004047  2.939095e-05   0.000050   0.000145   \n",
       "2   0.002289   0.000205   0.003236  9.213272e-06   0.000015   0.000065   \n",
       "3   0.008099   0.005975   0.010004  1.036999e-03   0.000562   0.001518   \n",
       "4   0.000284   0.000006   0.000977  8.200367e-07   0.000002   0.000003   \n",
       "\n",
       "   Class11.6  \n",
       "0   0.064111  \n",
       "1   0.012347  \n",
       "2   0.006813  \n",
       "3   0.043148  \n",
       "4   0.000624  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results.to_csv(path_data + 'results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
